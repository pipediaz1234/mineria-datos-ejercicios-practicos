# -*- coding: utf-8 -*-
"""EJERCICIO #3 REGRESION LOGARITMICA .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18Pwo9C1rodZrunEc5YfiBjfjRUp3Jx9c
"""

# ============================================================================
# EJERCICIO #3: REGRESIÓN LOGARÍTMICA
# Modelar relación entre inversión en publicidad y ventas
# ============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from scipy import stats
from google.colab import files
import io
import warnings
warnings.filterwarnings('ignore')

# Configuración de visualización
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (15, 5)
plt.rcParams['font.size'] = 10

print("╔" + "="*78 + "╗")
print("║" + " "*25 + "EJERCICIO #3: REGRESIÓN LOGARÍTMICA" + " "*22 + "║")
print("║" + " "*20 + "Modelo: Inversión en Publicidad vs Ventas" + " "*20 + "║")
print("╚" + "="*78 + "╝")

# ============================================================================
# PASO 1: IMPORTAR Y EXAMINAR LOS DATOS
# ============================================================================
print("\n" + "┌" + "─"*78 + "┐")
print("│ PASO 1: IMPORTAR Y EXAMINAR LOS DATOS" + " "*39 + "│")
print("└" + "─"*78 + "┘")

print("\n Por favor, sube el archivo 'S8_datos_regresion_logaritmica.xlsx'")
print("   (Se abrirá un cuadro de diálogo para seleccionar el archivo)\n")

# Subir archivo Excel
uploaded = files.upload()
file_name = list(uploaded.keys())[0]

# Leer archivo Excel
data = pd.read_excel(io.BytesIO(uploaded[file_name]))

print(f"\n✓ Archivo cargado exitosamente: {file_name}")
print(f"\n{'='*78}")
print(" INFORMACIÓN GENERAL DEL DATASET")
print("="*78)
print(f"   • Dimensiones: {data.shape[0]} filas × {data.shape[1]} columnas")
print(f"   • Variables detectadas: {list(data.columns)}")

# IDENTIFICAR COLUMNAS NUMÉRICAS
print("\n" + "─"*78)
print(" IDENTIFICACIÓN DE VARIABLES")
print("─"*78)

columnas_numericas = data.select_dtypes(include=[np.number]).columns.tolist()

print(f"\n   Columnas NUMÉRICAS ({len(columnas_numericas)}):")
for col in columnas_numericas:
    print(f"     • {col}")

# ASIGNACIÓN AUTOMÁTICA INTELIGENTE
print("\n" + "─"*78)
print(" ASIGNACIÓN DE VARIABLES")
print("─"*78)

# Buscar variables por nombres comunes o patrones
nombre_inversion = None
nombre_ventas = None

# Buscar por nombres comunes
nombres_inversion = ['inversion', 'publicidad', 'gasto', 'investment', 'advertising', 'spending']
nombres_ventas = ['ventas', 'sales', 'ingresos', 'revenue', 'ganancias']

for col in columnas_numericas:
    col_lower = col.lower()
    if any(nombre in col_lower for nombre in nombres_inversion):
        nombre_inversion = col
    elif any(nombre in col_lower for nombre in nombres_ventas):
        nombre_ventas = col

# Si no se encontraron por nombre, asignar por posición
if nombre_inversion is None and len(columnas_numericas) >= 2:
    nombre_inversion = columnas_numericas[0]
if nombre_ventas is None and len(columnas_numericas) >= 2:
    nombre_ventas = columnas_numericas[1]

print(f"\n   ✓ Variables asignadas:")
print(f"   • Variable Independiente (Inversión): {nombre_inversion}")
print(f"   • Variable Dependiente (Ventas):      {nombre_ventas}")

# Verificar que tenemos ambas variables
if nombre_inversion is None or nombre_ventas is None:
    print("\n   ❌ ERROR: No se pudieron identificar las variables necesarias")
    print(f"   Columnas disponibles: {columnas_numericas}")
    raise ValueError("No se pudieron identificar las variables de inversión y ventas")

print("\n" + "─"*78)
print(" PRIMERAS 10 FILAS DEL DATASET")
print("─"*78)
print(data.head(10).to_string())

print("\n" + "─"*78)
print(" ESTADÍSTICAS DESCRIPTIVAS")
print("─"*78)
print(data[[nombre_inversion, nombre_ventas]].describe().to_string())

# Verificar calidad de datos
print("\n" + "─"*78)
print(" VERIFICACIÓN DE CALIDAD")
print("─"*78)
valores_nulos = data[[nombre_inversion, nombre_ventas]].isnull().sum()
if valores_nulos.sum() == 0:
    print("   ✓ No se encontraron valores nulos")
else:
    print("   ⚠ Valores nulos encontrados:")
    for col, nulos in valores_nulos.items():
        if nulos > 0:
            print(f"     • {col}: {nulos} valores nulos")

# Verificar valores no positivos para la transformación logarítmica
valores_no_positivos = (data[nombre_inversion] <= 0).sum()
if valores_no_positivos > 0:
    print(f"   ⚠ Advertencia: {valores_no_positivos} valores no positivos en {nombre_inversion}")
    print("   Esto puede causar problemas con la transformación logarítmica")
else:
    print("   ✓ Todos los valores de inversión son positivos (adecuados para transformación logarítmica)")

# Visualización inicial: Distribuciones y relación original
print("\n Generando visualizaciones iniciales...")
fig, axes = plt.subplots(2, 2, figsize=(16, 10))

# Distribución de Inversión
axes[0, 0].hist(data[nombre_inversion], bins=30, color='skyblue', edgecolor='black', alpha=0.7)
axes[0, 0].axvline(data[nombre_inversion].mean(), color='red', linestyle='--',
                   linewidth=2, label=f'Media: {data[nombre_inversion].mean():.2f}')
axes[0, 0].set_xlabel(f'{nombre_inversion}', fontsize=11)
axes[0, 0].set_ylabel('Frecuencia', fontsize=11)
axes[0, 0].set_title(f'Distribución: {nombre_inversion}\n(Variable Independiente)',
                     fontsize=12, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# Distribución de Ventas
axes[0, 1].hist(data[nombre_ventas], bins=30, color='lightcoral', edgecolor='black', alpha=0.7)
axes[0, 1].axvline(data[nombre_ventas].mean(), color='red', linestyle='--',
                   linewidth=2, label=f'Media: {data[nombre_ventas].mean():.2f}')
axes[0, 1].set_xlabel(f'{nombre_ventas}', fontsize=11)
axes[0, 1].set_ylabel('Frecuencia', fontsize=11)
axes[0, 1].set_title(f'Distribución: {nombre_ventas}\n(Variable Dependiente)',
                     fontsize=12, fontweight='bold')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Relación original sin transformar
axes[1, 0].scatter(data[nombre_inversion], data[nombre_ventas], alpha=0.6, s=60,
                   color='blue', edgecolors='black', linewidths=0.5)
axes[1, 0].set_xlabel(nombre_inversion, fontsize=11)
axes[1, 0].set_ylabel(nombre_ventas, fontsize=11)
axes[1, 0].set_title(f'Relación Original: {nombre_inversion} vs {nombre_ventas}',
                     fontsize=12, fontweight='bold')
axes[1, 0].grid(True, alpha=0.3)

# Boxplot para detectar outliers
data_boxplot = data[[nombre_inversion, nombre_ventas]].copy()
# Estandarizar para mejor visualización
data_boxplot_std = (data_boxplot - data_boxplot.mean()) / data_boxplot.std()
bp = axes[1, 1].boxplot(data_boxplot_std.values, labels=[nombre_inversion, nombre_ventas],
                       patch_artist=True,
                       boxprops=dict(facecolor='lightgreen', alpha=0.7),
                       medianprops=dict(color='red', linewidth=2))
axes[1, 1].set_ylabel('Valores Estandarizados', fontsize=11)
axes[1, 1].set_title('Detección de Outliers\n(Valores Estandarizados)',
                     fontsize=12, fontweight='bold')
axes[1, 1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()

# ============================================================================
# PASO 2: TRANSFORMACIÓN LOGARÍTMICA
# ============================================================================
print("\n\n" + "┌" + "─"*78 + "┐")
print("│ PASO 2: TRANSFORMACIÓN LOGARÍTMICA" + " "*42 + "│")
print("└" + "─"*78 + "┘")

print("\n" + "="*78)
print(" FUNDAMENTO TEÓRICO")
print("="*78)
print("\n   La regresión logarítmica modela relaciones donde:")
print("   • El crecimiento no es lineal")
print("   • Los incrementos tienen efectos decrecientes")
print("   • Se expresa como: Ventas = β₀ + β₁ × ln(Inversión)")

# Aplicar transformación logarítmica
print("\n" + "─"*78)
print(" APLICANDO TRANSFORMACIÓN LOGARÍTMICA")
print("─"*78)

# Verificar y manejar valores no positivos
if (data[nombre_inversion] <= 0).any():
    print(f"   ⚠ Se encontraron { (data[nombre_inversion] <= 0).sum() } valores no positivos")
    print("   ✓ Ajustando datos para evitar problemas con el logaritmo...")
    # Agregar una constante pequeña para evitar log(0) o log(negativo)
    inversion_ajustada = data[nombre_inversion] + 0.001
    data['Inversion_Ajustada'] = inversion_ajustada
    data['ln_Inversion'] = np.log(inversion_ajustada)
    print("   ✓ Transformación aplicada con ajuste para valores no positivos")
else:
    data['ln_Inversion'] = np.log(data[nombre_inversion])
    print("   ✓ Transformación logarítmica aplicada directamente")

print(f"\n   Se creó la variable: ln_Inversion = ln({nombre_inversion})")

# Mostrar estadísticas de la transformación
print("\n" + "─"*78)
print(" COMPARACIÓN: VARIABLE ORIGINAL VS TRANSFORMADA")
print("─"*78)
comparacion_stats = pd.DataFrame({
    'Estadística': ['Mínimo', 'Máximo', 'Media', 'Desviación Estándar'],
    nombre_inversion: [
        data[nombre_inversion].min(),
        data[nombre_inversion].max(),
        data[nombre_inversion].mean(),
        data[nombre_inversion].std()
    ],
    'ln_Inversion': [
        data['ln_Inversion'].min(),
        data['ln_Inversion'].max(),
        data['ln_Inversion'].mean(),
        data['ln_Inversion'].std()
    ]
})
print(comparacion_stats.to_string(index=False))

# Visualización de la transformación
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Antes de la transformación
axes[0].scatter(data[nombre_inversion], data[nombre_ventas], alpha=0.6, s=60,
                color='blue', edgecolors='black', linewidths=0.5)
axes[0].set_xlabel(nombre_inversion, fontsize=11)
axes[0].set_ylabel(nombre_ventas, fontsize=11)
axes[0].set_title('Relación Original\n(Antes de Transformación)',
                  fontsize=12, fontweight='bold')
axes[0].grid(True, alpha=0.3)

# Después de la transformación
axes[1].scatter(data['ln_Inversion'], data[nombre_ventas], alpha=0.6, s=60,
                color='green', edgecolors='black', linewidths=0.5)
axes[1].set_xlabel('ln_Inversion', fontsize=11)
axes[1].set_ylabel(nombre_ventas, fontsize=11)
axes[1].set_title('Relación después de Transformación Logarítmica',
                  fontsize=12, fontweight='bold')
axes[1].grid(True, alpha=0.3)

# Comparación lado a lado
axes[2].hist(data[nombre_inversion], bins=30, alpha=0.6, color='blue',
             label='Original', edgecolor='black')
axes[2].hist(data['ln_Inversion'], bins=30, alpha=0.6, color='green',
             label='Logarítmica', edgecolor='black')
axes[2].set_xlabel('Valores', fontsize=11)
axes[2].set_ylabel('Frecuencia', fontsize=11)
axes[2].set_title('Comparación de Distribuciones\nOriginal vs Logarítmica',
                  fontsize=12, fontweight='bold')
axes[2].legend()
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# AJUSTAR EL MODELO DE REGRESIÓN
print("\n" + "─"*78)
print(" AJUSTANDO MODELO DE REGRESIÓN LOGARÍTMICA")
print("─"*78)

# Preparar datos para el modelo
X_log = data[['ln_Inversion']]
y = data[nombre_ventas]

print(f"\n   Variables para el modelo:")
print(f"   • X (predictor): ln_Inversion")
print(f"   • y (objetivo):  {nombre_ventas}")
print(f"   • Dimensiones: X = {X_log.shape}, y = {y.shape}")

# Ajustar modelo
modelo_log = LinearRegression()
modelo_log.fit(X_log, y)
y_pred_log = modelo_log.predict(X_log)

print("✓ Modelo de regresión logarítmica ajustado exitosamente!")

print("\n" + "="*78)
print(" ECUACIÓN DEL MODELO LOGARÍTMICO")
print("="*78)
print(f"\n   {nombre_ventas} = {modelo_log.intercept_:.2f} + {modelo_log.coef_[0]:.2f} × ln({nombre_inversion})")
print(f"\n   O equivalentemente:")
print(f"   {nombre_ventas} = {modelo_log.intercept_:.2f} + {modelo_log.coef_[0]:.2f} × log({nombre_inversion})")

print("\n" + "─"*78)
print(" PARÁMETROS DEL MODELO")
print("─"*78)
print(f"   β₀ (Intercepto):              {modelo_log.intercept_:>10.4f}")
print(f"   β₁ (Coeficiente logarítmico): {modelo_log.coef_[0]:>10.4f}")

print("\n" + "─"*78)
print(" INTERPRETACIÓN DE PARÁMETROS")
print("─"*78)
print(f"\n   1. Intercepto (β₀ = {modelo_log.intercept_:.2f}):")
print(f"      • Representa el valor esperado de {nombre_ventas} cuando ln({nombre_inversion}) = 0")
print(f"      • Equivale a {nombre_inversion} = 1 unidad (ya que ln(1) = 0)")

print(f"\n   2. Coeficiente Logarítmico (β₁ = {modelo_log.coef_[0]:.4f}):")
print(f"      • Por cada aumento de 1% en {nombre_inversion},")
print(f"        las {nombre_ventas} aumentan aproximadamente {modelo_log.coef_[0]/100:.4f} unidades")
print(f"      • Indica la tasa de cambio de {nombre_ventas} con respecto al logaritmo de {nombre_inversion}")

# ============================================================================
# PASO 3: EVALUAR EL MODELO
# ============================================================================
print("\n\n" + "┌" + "─"*78 + "┐")
print("│ PASO 3: EVALUAR EL MODELO" + " "*51 + "│")
print("└" + "─"*78 + "┘")

print("\n" + "="*78)
print(" MÉTRICAS DE DESEMPEÑO")
print("="*78)

# Calcular métricas
r2_log = r2_score(y, y_pred_log)
mse_log = mean_squared_error(y, y_pred_log)
rmse_log = np.sqrt(mse_log)
mae_log = mean_absolute_error(y, y_pred_log)

print(f"\n   R² (Coeficiente de Determinación):    {r2_log:.6f}")
print(f"   → El modelo explica el {r2_log*100:.2f}% de la variabilidad en {nombre_ventas}")

print(f"\n   MSE (Error Cuadrático Medio):         {mse_log:.2f}")
print(f"   RMSE (Raíz del MSE):                  {rmse_log:.2f}")
print(f"   → Error promedio de predicción: ±{rmse_log:.2f} unidades")

print(f"\n   MAE (Error Absoluto Medio):           {mae_log:.2f}")

print(f"\n   Ventas Medias:                        {y.mean():.2f}")
print(f"   Error Relativo:                       {(rmse_log/y.mean())*100:.2f}%")

# Análisis de residuos
residuos_log = y - y_pred_log
print("\n" + "─"*78)
print(" ANÁLISIS DE RESIDUOS")
print("─"*78)
print(f"   Media de residuos:                    {residuos_log.mean():.4f}")
print(f"   (Debe ser cercano a 0 para un buen modelo)")
print(f"\n   Desviación estándar:                  {residuos_log.std():.4f}")
print(f"   Mínimo residuo:                       {residuos_log.min():.2f}")
print(f"   Máximo residuo:                       {residuos_log.max():.2f}")

# Test de normalidad de residuos
stat_shapiro, p_value_log = stats.shapiro(residuos_log)
print(f"\n   Test de Normalidad (Shapiro-Wilk):")
print(f"   • Estadístico: {stat_shapiro:.4f}")
print(f"   • p-value: {p_value_log:.4f}")
if p_value_log > 0.05:
    print(f"   ✓ Los residuos siguen distribución normal (p > 0.05)")
else:
    print(f"   ⚠ Los residuos NO siguen distribución normal (p < 0.05)")

# Visualizaciones de evaluación
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Valores reales vs predichos
axes[0, 0].scatter(y, y_pred_log, alpha=0.6, s=60, color='purple', edgecolors='black', linewidths=0.5)
axes[0, 0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2.5, label='Predicción Perfecta')
axes[0, 0].set_xlabel(f'{nombre_ventas} Real', fontsize=11)
axes[0, 0].set_ylabel(f'{nombre_ventas} Predicho', fontsize=11)
axes[0, 0].set_title(f'Valores Reales vs Predichos\nR² = {r2_log:.4f}', fontsize=12, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# Residuos vs valores predichos
axes[0, 1].scatter(y_pred_log, residuos_log, alpha=0.6, s=60, color='orange', edgecolors='black', linewidths=0.5)
axes[0, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)
axes[0, 1].axhline(y=rmse_log, color='green', linestyle=':', linewidth=1.5, alpha=0.7, label=f'±RMSE')
axes[0, 1].axhline(y=-rmse_log, color='green', linestyle=':', linewidth=1.5, alpha=0.7)
axes[0, 1].set_xlabel('Valores Predichos', fontsize=11)
axes[0, 1].set_ylabel('Residuos', fontsize=11)
axes[0, 1].set_title('Residuos vs Valores Predichos\n(Homocedasticidad)', fontsize=12, fontweight='bold')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Distribución de residuos
axes[1, 0].hist(residuos_log, bins=30, color='teal', edgecolor='black', alpha=0.7, density=True)
mu, sigma = residuos_log.mean(), residuos_log.std()
x_norm = np.linspace(residuos_log.min(), residuos_log.max(), 100)
axes[1, 0].plot(x_norm, stats.norm.pdf(x_norm, mu, sigma), 'r-', linewidth=2, label='Normal Teórica')
axes[1, 0].axvline(mu, color='red', linestyle='--', linewidth=1.5, label=f'Media: {mu:.2f}')
axes[1, 0].set_xlabel('Residuos', fontsize=11)
axes[1, 0].set_ylabel('Densidad', fontsize=11)
axes[1, 0].set_title('Distribución de Residuos', fontsize=12, fontweight='bold')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# Q-Q plot
stats.probplot(residuos_log, dist="norm", plot=axes[1, 1])
axes[1, 1].get_lines()[0].set_markerfacecolor('blue')
axes[1, 1].get_lines()[0].set_markersize(6)
axes[1, 1].get_lines()[1].set_color('red')
axes[1, 1].get_lines()[1].set_linewidth(2)
axes[1, 1].set_title(f'Q-Q Plot de Residuos\nShapiro-Wilk p-value: {p_value_log:.4f}',
                     fontsize=12, fontweight='bold')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Visualización de la curva de regresión logarítmica
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# En escala logarítmica
axes[0].scatter(data['ln_Inversion'], y, alpha=0.6, s=60, color='blue',
                edgecolors='black', linewidths=0.5, label='Datos reales')
axes[0].plot(data['ln_Inversion'], y_pred_log, 'r-', linewidth=3, label='Regresión lineal')
axes[0].set_xlabel('ln_Inversion', fontsize=11)
axes[0].set_ylabel(nombre_ventas, fontsize=11)
axes[0].set_title('Regresión Lineal en Escala Logarítmica', fontsize=12, fontweight='bold')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# En escala original (curva logarítmica)
x_original_sorted = np.linspace(data[nombre_inversion].min(), data[nombre_inversion].max(), 100)
x_log_sorted = np.log(x_original_sorted)
y_pred_curve = modelo_log.intercept_ + modelo_log.coef_[0] * x_log_sorted

axes[1].scatter(data[nombre_inversion], y, alpha=0.6, s=60, color='green',
                edgecolors='black', linewidths=0.5, label='Datos reales')
axes[1].plot(x_original_sorted, y_pred_curve, 'r-', linewidth=3, label='Curva logarítmica')
axes[1].set_xlabel(nombre_inversion, fontsize=11)
axes[1].set_ylabel(nombre_ventas, fontsize=11)
axes[1].set_title('Curva de Regresión Logarítmica en Escala Original',
                  fontsize=12, fontweight='bold')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# ============================================================================
# PASO 4: PREDICCIONES
# ============================================================================
print("\n\n" + "┌" + "─"*78 + "┐")
print("│ PASO 4: REALIZAR PREDICCIONES" + " "*47 + "│")
print("└" + "─"*78 + "┘")

print("\n" + "="*78)
print(" PREDICCIONES CON DIFERENTES NIVELES DE INVERSIÓN")
print("="*78)

# Crear niveles de inversión para predicción
inversion_min = data[nombre_inversion].min()
inversion_max = data[nombre_inversion].max()
inversion_media = data[nombre_inversion].mean()

niveles_inversion = [
    inversion_min,
    inversion_min + (inversion_media - inversion_min) * 0.25,
    inversion_media,
    inversion_media + (inversion_max - inversion_media) * 0.25,
    inversion_max
]

print(f"\n   Niveles de inversión seleccionados:")
print(f"   • Mínimo: {inversion_min:.2f}")
print(f"   • 25% hacia media: {niveles_inversion[1]:.2f}")
print(f"   • Media: {inversion_media:.2f}")
print(f"   • 75% hacia máximo: {niveles_inversion[3]:.2f}")
print(f"   • Máximo: {inversion_max:.2f}")

print(f"\n   Predicciones de ventas:")
print(f"   ┌{'─'*20}┬{'─'*20}┬{'─'*20}┐")
print(f"   │ {nombre_inversion:18s} │ {'ln_Inversion':18s} │ {nombre_ventas+'_Pred':18s} │")
print(f"   ├{'─'*20}┼{'─'*20}┼{'─'*20}┤")

for inversion in niveles_inversion:
    ln_inversion = np.log(inversion)
    ventas_pred = modelo_log.intercept_ + modelo_log.coef_[0] * ln_inversion
    print(f"   │ {inversion:18.2f} │ {ln_inversion:18.4f} │ {ventas_pred:18.2f} │")

print(f"   └{'─'*20}┴{'─'*20}┴{'─'*20}┘")

# Predicciones para valores específicos
print(f"\n" + "─"*78)
print(" PREDICCIONES ESPECÍFICAS")
print("─"*78)

# Calcular incrementos porcentuales
print(f"\n   Efecto de incrementos en la inversión:")
inversion_base = inversion_media
incrementos = [0.05, 0.10, 0.20, 0.50]  # 5%, 10%, 20%, 50%

for incremento in incrementos:
    inversion_nueva = inversion_base * (1 + incremento)
    ln_base = np.log(inversion_base)
    ln_nueva = np.log(inversion_nueva)

    ventas_base = modelo_log.intercept_ + modelo_log.coef_[0] * ln_base
    ventas_nueva = modelo_log.intercept_ + modelo_log.coef_[0] * ln_nueva
    cambio_ventas = ventas_nueva - ventas_base
    cambio_porcentual = (cambio_ventas / ventas_base) * 100

    print(f"\n   • Incremento del {incremento*100:.0f}% en {nombre_inversion}:")
    print(f"     {nombre_inversion}: {inversion_base:.2f} → {inversion_nueva:.2f}")
    print(f"     {nombre_ventas}: {ventas_base:.2f} → {ventas_nueva:.2f}")
    print(f"     Cambio: {cambio_ventas:+.2f} ({cambio_porcentual:+.2f}%)")

print(f"\n" + "─"*78)
print(" COMPARACIÓN: PREDICCIONES VS VALORES REALES")
print("─"*78)

# Crear tabla de comparación
comparacion = pd.DataFrame({
    nombre_inversion: data[nombre_inversion].iloc[:10],
    'ln_Inversion': data['ln_Inversion'].iloc[:10],
    f'{nombre_ventas}_Real': y.iloc[:10],
    f'{nombre_ventas}_Pred': y_pred_log[:10],
    'Error': residuos_log.iloc[:10],
    'Error_%': (residuos_log.iloc[:10] / y.iloc[:10] * 100)
})

print(f"\n{comparacion.to_string(index=False)}")

# Análisis de precisión general
error_pct = np.abs(residuos_log / y * 100)
# Limpiar valores infinitos
error_pct_limpio = error_pct[np.isfinite(error_pct)]

print(f"\n" + "─"*78)
print(" ANÁLISIS DE PRECISIÓN")
print("─"*78)
print(f"   Error Porcentual Absoluto Medio:      {error_pct_limpio.mean():.2f}%")
print(f"   Error Porcentual Absoluto Mediano:    {error_pct_limpio.median():.2f}%")

# Porcentaje de predicciones dentro de rangos de error
dentro_5 = (error_pct_limpio <= 5).sum() / len(error_pct_limpio) * 100
dentro_10 = (error_pct_limpio <= 10).sum() / len(error_pct_limpio) * 100
dentro_15 = (error_pct_limpio <= 15).sum() / len(error_pct_limpio) * 100

print(f"\n   Predicciones con error ≤ 5%:          {dentro_5:.1f}%")
print(f"   Predicciones con error ≤ 10%:         {dentro_10:.1f}%")
print(f"   Predicciones con error ≤ 15%:         {dentro_15:.1f}%")

# Visualización final de predicciones
plt.figure(figsize=(14, 8))

# Gráfico de dispersión con curva de regresión
plt.scatter(data[nombre_inversion], y, alpha=0.6, s=80,
           color='blue', edgecolors='black', linewidths=0.8, label='Datos Reales')

# Curva de regresión logarítmica
x_curve = np.linspace(data[nombre_inversion].min() * 0.9, data[nombre_inversion].max() * 1.1, 200)
y_curve = modelo_log.intercept_ + modelo_log.coef_[0] * np.log(x_curve)
plt.plot(x_curve, y_curve, 'r-', linewidth=3, label='Curva de Regresión Logarítmica')

# Líneas de predicción para puntos específicos
for i, inversion in enumerate(niveles_inversion):
    ventas_pred = modelo_log.intercept_ + modelo_log.coef_[0] * np.log(inversion)
    plt.plot([inversion, inversion], [0, ventas_pred], 'g--', alpha=0.7, linewidth=1)
    plt.plot(inversion, ventas_pred, 'ro', markersize=8, markeredgecolor='black')
    plt.annotate(f'({inversion:.1f}, {ventas_pred:.1f})',
                (inversion, ventas_pred),
                xytext=(10, 10), textcoords='offset points',
                fontsize=9, bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7))

plt.xlabel(nombre_inversion, fontsize=12)
plt.ylabel(nombre_ventas, fontsize=12)
plt.title(f'Modelo de Regresión Logarítmica: {nombre_inversion} vs {nombre_ventas}\nR² = {r2_log:.4f}',
          fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# ============================================================================
# RESUMEN EJECUTIVO
# ============================================================================
print("\n\n" + "╔" + "="*78 + "╗")
print("║" + " "*25 + "RESUMEN EJECUTIVO" + " "*35 + "║")
print("╚" + "="*78 + "╝")

print("\n" + "─"*78)
print(" ECUACIÓN FINAL DEL MODELO LOGARÍTMICO")
print("─"*78)
print(f"\n   {nombre_ventas} = {modelo_log.intercept_:.2f} + {modelo_log.coef_[0]:.2f} × ln({nombre_inversion})")

print("\n" + "─"*78)
print(" RENDIMIENTO DEL MODELO")
print("─"*78)
print(f"   R² (Bondad de ajuste):                {r2_log:.4f} ({r2_log*100:.2f}%)")
print(f"   Error Promedio (RMSE):                {rmse_log:.2f}")
print(f"   Error Relativo:                       {(rmse_log/y.mean())*100:.2f}%")
print(f"   Predicciones con error ≤10%:          {dentro_10:.1f}%")

print("\n" + "─"*78)
print(" INTERPRETACIÓN DEL COEFICIENTE LOGARÍTMICO")
print("─"*78)
print(f"   Coeficiente β₁ = {modelo_log.coef_[0]:.4f}")
print(f"   • Por cada 1% de aumento en {nombre_inversion},")
print(f"     las {nombre_ventas} aumentan aproximadamente {modelo_log.coef_[0]/100:.4f} unidades")
print(f"   • Indica rendimientos decrecientes: incrementos iguales en inversión")
print(f"     producen aumentos cada vez menores en ventas")

print("\n" + "─"*78)
print(" VALIDACIÓN DEL MODELO")
print("─"*78)
print(f"   Test de Normalidad (Shapiro-Wilk):")
print(f"   • p-value = {p_value_log:.4f}")
print(f"   • Resultado: {'✓ Residuos normales' if p_value_log > 0.05 else '⚠ Residuos no normales'}")

print(f"\n   Media de residuos: {residuos_log.mean():.4f}")
print(f"   {'✓ Cercana a cero (modelo bien ajustado)' if abs(residuos_log.mean()) < 0.1 else '⚠ Alejada de cero (posible sesgo)'}")

print("\n" + "─"*78)
print(" RECOMENDACIONES")
print("─"*78)

if r2_log > 0.8:
    print("   ✓ Excelente ajuste del modelo (R² > 0.8)")
elif r2_log > 0.6:
    print("   ✓ Buen ajuste del modelo (R² > 0.6)")
elif r2_log > 0.4:
    print("   ⚠ Ajuste moderado (R² > 0.4) - La relación logarítmica es apropiada")
else:
    print("   ⚠ Ajuste débil (R² < 0.4) - Considerar otras transformaciones")

if dentro_10 > 70:
    print(f"   ✓ Alta precisión: {dentro_10:.1f}% de predicciones con error ≤10%")
elif dentro_10 > 50:
    print(f"   ✓ Precisión aceptable: {dentro_10:.1f}% de predicciones con error ≤10%")
else:
    print(f"   ⚠ Baja precisión: Solo {dentro_10:.1f}% de predicciones con error ≤10%")

print(f"\n   El modelo logarítmico es apropiado cuando:")
print(f"   • Existen rendimientos decrecientes de la inversión")
print(f"   • Los incrementos iniciales tienen mayor impacto")
print(f"   • Se quiere modelar saturación en el efecto de la inversión")

print("\n" + "="*78)
print(" ANÁLISIS COMPLETADO EXITOSAMENTE")
print("="*78)

print(f"\n   Total de observaciones:              {len(data)}")
print(f"   Variable independiente:              {nombre_inversion}")
print(f"   Variable dependiente:                {nombre_ventas}")
print(f"   Transformación aplicada:             ln({nombre_inversion})")
print(f"   Calidad del modelo (R²):             {r2_log*100:.2f}%")
print(f"   Error promedio de predicción (RMSE): {rmse_log:.2f}")

print("\n" + "─"*78)